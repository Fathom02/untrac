{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2a4046a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "from collections import Counter\n",
    "\n",
    "from torch.utils.data import RandomSampler\n",
    "import datasets\n",
    "from datasets import load_dataset, concatenate_datasets, Dataset, DatasetDict\n",
    "from transformers import (\n",
    "    set_seed,\n",
    ")\n",
    "set_seed(seed=42)\n",
    "\n",
    "def sample_dataset(dataset, num_samples, generator=None, dataset_name=None):\n",
    "    sampler = RandomSampler(dataset, num_samples=num_samples, generator=generator)\n",
    "    sampled_dataset = dataset.select(sampler)\n",
    "    if dataset_name is not None: sampled_dataset = sampled_dataset.map(lambda ex: {\"dataset\": dataset_name})\n",
    "    return sampled_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396f24f8",
   "metadata": {},
   "source": [
    "# ToxiGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "972bf2c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m-isonuma/.conda/envs/untrac/lib/python3.8/site-packages/datasets/load.py:2089: FutureWarning: 'use_auth_token' was deprecated in favor of 'token' in version 2.14.0 and will be removed in 3.0.0.\n",
      "You can remove this warning by passing 'token=True' instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "toxigen_dataset = load_dataset(\"skg/toxigen-data\", name=\"train\", use_auth_token=True, split=\"train\")\n",
    "toxigen_dataset = toxigen_dataset.filter(lambda ex: ex[\"prompt_label\"] == 1)\n",
    "\n",
    "groups = toxigen_dataset.unique(\"group\")\n",
    "toxigen_datasets = DatasetDict({group: toxigen_dataset.filter(lambda ex: ex[\"group\"] == group) for group in groups})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f261e1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_dataset(dataset, num_samples=None):\n",
    "    dataset = dataset.rename_column(\"generation\", \"inputs_pretokenized\")\n",
    "    dataset = dataset.rename_column(\"group\", \"dataset\")\n",
    "    dataset = dataset.remove_columns([column for column in dataset.column_names if column not in [\"inputs_pretokenized\", \"dataset\"]])\n",
    "    \n",
    "    if num_samples is not None: dataset = sample_dataset(dataset, num_samples=num_samples)\n",
    "    return dataset\n",
    "\n",
    "toxigen_datasets = toxigen_datasets.map(lambda ex: {\"length\": len(ex[\"generation\"].split(\" \"))})\n",
    "toxigen_datasets = toxigen_datasets.sort(\"length\")\n",
    "toxigen_datasets = toxigen_datasets.filter(lambda ex: ex[\"length\"] > 8 and ex[\"length\"] <= 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7e53574f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m-isonuma/.conda/envs/untrac/lib/python3.8/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/m-isonuma/.conda/envs/untrac/lib/python3.8/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████| 3328/3328 [00:00<00:00, 198620.39 examples/s]\n"
     ]
    }
   ],
   "source": [
    "toxigen_dataset = concatenate_datasets([preprocess_dataset(dataset, num_samples=256) for dataset_name, dataset in toxigen_datasets.items()])\n",
    "toxigen_dataset.save_to_disk(\"data/toxigen_test_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a9ebb7",
   "metadata": {},
   "source": [
    "# WinoBias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd8c478b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████████████████████████████████████████████████| 21.5k/21.5k [00:00<00:00, 19.7MB/s]\n",
      "Downloading data files:   0%|                                                                 | 0/2 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|                                                                 | 0.00/31.8k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████| 31.8k/31.8k [00:01<00:00, 27.6kB/s]\u001b[A\n",
      "Downloading data files:  50%|████████████████████████████▌                            | 1/2 [00:01<00:01,  1.16s/it]\n",
      "Downloading data:   0%|                                                                 | 0.00/33.8k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████| 33.8k/33.8k [00:01<00:00, 31.4kB/s]\u001b[A\n",
      "Downloading data files: 100%|█████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.12s/it]\n",
      "Extracting data files: 100%|████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1238.72it/s]\n",
      "Generating validation split: 100%|██████████████████████████████████████| 396/396 [00:00<00:00, 24692.18 examples/s]\n",
      "Generating test split: 100%|████████████████████████████████████████████| 396/396 [00:00<00:00, 81953.14 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████| 792/792 [00:00<00:00, 8919.02 examples/s]\n",
      "Downloading data files:   0%|                                                                 | 0/2 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|                                                                 | 0.00/31.6k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████| 31.6k/31.6k [00:01<00:00, 28.4kB/s]\u001b[A\n",
      "Downloading data files:  50%|████████████████████████████▌                            | 1/2 [00:01<00:01,  1.12s/it]\n",
      "Downloading data:   0%|                                                                 | 0.00/33.8k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|████████████████████████████████████████████████████████| 33.8k/33.8k [00:01<00:00, 31.0kB/s]\u001b[A\n",
      "Downloading data files: 100%|█████████████████████████████████████████████████████████| 2/2 [00:02<00:00,  1.11s/it]\n",
      "Extracting data files: 100%|████████████████████████████████████████████████████████| 2/2 [00:00<00:00, 1234.71it/s]\n",
      "Generating validation split: 100%|██████████████████████████████████████| 396/396 [00:00<00:00, 72183.59 examples/s]\n",
      "Generating test split: 100%|███████████████████████████████████████████| 396/396 [00:00<00:00, 112698.09 examples/s]\n",
      "Map: 100%|███████████████████████████████████████████████████████████████| 792/792 [00:00<00:00, 4612.50 examples/s]\n"
     ]
    }
   ],
   "source": [
    "pro_dataset = load_dataset(\"wino_bias\", name=\"type1_pro\", split=\"validation+test\")\n",
    "pro_dataset = pro_dataset.map(lambda ex: {\"inputs_pretokenized\": \" \".join(ex[\"tokens\"]), \"type\": \"pro\"})\n",
    "\n",
    "anti_dataset = load_dataset(\"wino_bias\", name=\"type1_anti\", split=\"validation+test\")\n",
    "anti_dataset = anti_dataset.map(lambda ex: {\"inputs_pretokenized\": \" \".join(ex[\"tokens\"]), \"type\": \"anti\"})\n",
    "\n",
    "winobias_dataset = concatenate_datasets([pro_dataset, anti_dataset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88a10402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|█████████████████████████████████████████████████████████████| 1584/1584 [00:00<00:00, 8041.66 examples/s]\n",
      "Filter: 100%|█████████████████████████████████████████████████████████| 1584/1584 [00:00<00:00, 13519.96 examples/s]\n",
      "Flattening the indices: 100%|█████████████████████████████████████████| 1583/1583 [00:00<00:00, 98176.57 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████████████| 1583/1583 [00:00<00:00, 170319.97 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████████████| 1583/1583 [00:00<00:00, 170058.22 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████████████| 1583/1583 [00:00<00:00, 172197.29 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████████████| 1583/1583 [00:00<00:00, 167750.97 examples/s]\n"
     ]
    }
   ],
   "source": [
    "def coref(ex):\n",
    "    female = any([coref in ex[\"tokens\"] for coref in [\"she\", \"her\"]])\n",
    "    male = any([coref in ex[\"tokens\"] for coref in [\"he\", \"his\", \"him\"]])\n",
    "    if female and not male:\n",
    "        dataset = ex[\"type\"] + \"_female\"\n",
    "    elif male and not female:\n",
    "        dataset = ex[\"type\"] + \"_male\"\n",
    "    else:\n",
    "        dataset = None\n",
    "    \n",
    "    return {\"dataset\": dataset}\n",
    "\n",
    "winobias_dataset = winobias_dataset.map(coref)\n",
    "winobias_dataset = winobias_dataset.filter(lambda ex: ex[\"dataset\"] is not None)\n",
    "winobias_dataset = winobias_dataset.remove_columns([column for column in winobias_dataset.column_names if column not in [\"inputs_pretokenized\", \"targets_pretokenized\", \"dataset\"]])\n",
    "winobias_datasets = {\n",
    "    dataset: winobias_dataset.filter(lambda ex: ex[\"dataset\"] == dataset)\n",
    "    for dataset in winobias_dataset.unique(\"dataset\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "409b52be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████| 1024/1024 [00:00<00:00, 198262.81 examples/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = concatenate_datasets([sample_dataset(dataset, num_samples=256) for dataset_name, dataset in winobias_datasets.items()])\n",
    "test_dataset.save_to_disk(\"data/winobias_test_dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58f04e0",
   "metadata": {},
   "source": [
    "# TruthfulQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cd1a10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████████████████████████████████████████████████| 9.59k/9.59k [00:00<00:00, 17.6MB/s]\n",
      "Downloading data files:   0%|                                                                 | 0/1 [00:00<?, ?it/s]\n",
      "Downloading data:   0%|                                                                  | 0.00/223k [00:00<?, ?B/s]\u001b[A\n",
      "Downloading data: 100%|███████████████████████████████████████████████████████████| 223k/223k [00:00<00:00, 233kB/s]\u001b[A\n",
      "Downloading data files: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00,  1.04it/s]\n",
      "Extracting data files: 100%|█████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 967.54it/s]\n",
      "Generating validation split: 100%|█████████████████████████████████████| 817/817 [00:00<00:00, 192168.37 examples/s]\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = load_dataset(\"truthful_qa\", name=\"generation\", split=\"validation\")\n",
    "\n",
    "truthfulqa_dataset = []\n",
    "for ex in raw_dataset:\n",
    "    if \"Indexical Error\" in ex[\"category\"]:\n",
    "        dataset_name = \"indexical_error\"\n",
    "    elif \"Confusion\" in ex[\"category\"]:\n",
    "        dataset_name = \"confusion\"\n",
    "    else:\n",
    "        dataset_name = ex[\"category\"].lower()\n",
    "    \n",
    "    for incorrect_answer in ex[\"incorrect_answers\"]:\n",
    "        truthfulqa_dataset.append({\"inputs_pretokenized\": ex[\"question\"].strip(), \"targets_pretokenized\": incorrect_answer.strip(), \"dataset\": dataset_name})\n",
    "truthfulqa_dataset = Dataset.from_list(truthfulqa_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b79a3b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|████████████████████████████████████████████████████████| 3318/3318 [00:00<00:00, 302188.80 examples/s]\n",
      "Flattening the indices: 100%|████████████████████████████████████████| 1976/1976 [00:00<00:00, 118960.02 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████████████| 1976/1976 [00:00<00:00, 108114.44 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████████████| 1976/1976 [00:00<00:00, 142160.29 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████████████| 1976/1976 [00:00<00:00, 143740.69 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████████████| 1976/1976 [00:00<00:00, 143427.27 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████████████| 1976/1976 [00:00<00:00, 138137.02 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████████████| 1976/1976 [00:00<00:00, 141049.79 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████████████| 1976/1976 [00:00<00:00, 140311.92 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████████████| 1976/1976 [00:00<00:00, 140342.81 examples/s]\n",
      "Filter: 100%|████████████████████████████████████████████████████████| 1976/1976 [00:00<00:00, 143925.41 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset_names = [dataset_name for dataset_name, count in Counter(truthfulqa_dataset[\"dataset\"]).items() if count>=128]\n",
    "truthfulqa_dataset = truthfulqa_dataset.filter(lambda ex: ex[\"dataset\"] in dataset_names)\n",
    "\n",
    "truthfulqa_datasets = {\n",
    "    dataset: truthfulqa_dataset.filter(lambda ex: ex[\"dataset\"] == dataset)\n",
    "    for dataset in truthfulqa_dataset.unique(\"dataset\")\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29b11235",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/m-isonuma/.conda/envs/untrac/lib/python3.8/site-packages/datasets/table.py:1395: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  block_group = [InMemoryTable(cls._concat_blocks(list(block_group), axis=axis))]\n",
      "/home/m-isonuma/.conda/envs/untrac/lib/python3.8/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by promote_options='default'.\n",
      "  table = cls._concat_blocks(blocks, axis=0)\n",
      "Saving the dataset (1/1 shards): 100%|███████████████████████████████| 2304/2304 [00:00<00:00, 156961.95 examples/s]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = concatenate_datasets([sample_dataset(dataset, num_samples=256) for dataset_name, dataset in truthfulqa_datasets.items()])\n",
    "test_dataset.save_to_disk(\"data/truthfulqa_test_dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9748c7da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "untrac",
   "language": "python",
   "name": "untrac"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
